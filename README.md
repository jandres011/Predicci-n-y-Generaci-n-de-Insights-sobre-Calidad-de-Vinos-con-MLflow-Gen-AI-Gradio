# Proyecto Final: PredicciÃ³n y GeneraciÃ³n de Insights sobre Calidad de Vinos
## MLOps con MLflow + Gen AI + Gradio

Este proyecto implementa un pipeline completo de MLOps para predecir la calidad de vinos blancos a partir de sus propiedades quÃ­micas, integrando experimentaciÃ³n reproducible, registro de modelos, interfaz de usuario interactiva y explicaciones generadas por inteligencia artificial.

---

## Objetivo

Desarrollar un sistema end-to-end que:

- Entrene y compare modelos de machine learning con MLflow Tracking.
- Registre y versione el mejor modelo en MLflow Model Registry.
- Exponga predicciones a usuarios finales mediante una interfaz Gradio.
- Genere explicaciones automÃ¡ticas usando un LLM local (Ollama) para mejorar la interpretabilidad.
- Siga buenas prÃ¡cticas de reproducibilidad, modularidad y documentaciÃ³n.

---

## TecnologÃ­as Utilizadas

- **MLflow**: Tracking, Projects, Model Registry, Artifacts
- **Scikit-learn**: Random Forest Regressor
- **Gradio**: Interfaz web interactiva
- **Ollama (con llama3)**: GeneraciÃ³n de explicaciones con IA generativa
- **Pandas / NumPy / Matplotlib**: AnÃ¡lisis y visualizaciÃ³n
- **Conda**: GestiÃ³n de entorno reproducible

---

## Estructura del Proyecto

.
â”œâ”€â”€ data/ # Dataset: winequality-white.csv
â”œâ”€â”€ notebooks/ # AnÃ¡lisis exploratorio (Jupyter)
â”œâ”€â”€ src/ # CÃ³digo fuente modular
â”‚ â”œâ”€â”€ train.py # Entrenamiento con MLflow Tracking
â”‚ â”œâ”€â”€ utils.py # Funciones compartidas (carga de datos, etc.)
â”‚ â”œâ”€â”€ genai_explainer.py # MÃ³dulo de explicaciones con LLM
â”‚ â””â”€â”€ evaluate.py # (Opcional) EvaluaciÃ³n post-registro
â”œâ”€â”€ gradio_app/ # AplicaciÃ³n de usuario final
â”‚ â””â”€â”€ app.py # Interfaz con modelo desde Model Registry
â”œâ”€â”€ MLproject # DefiniciÃ³n de MLflow Project
â”œâ”€â”€ conda.yaml # Entorno reproducible
â”œâ”€â”€ README.md # Este archivo
â”œâ”€â”€ informe.pdf # Informe final del proyecto
â””â”€â”€ demo.mp4 # Video demostrativo (â‰¤3 min)

yaml
Copiar cÃ³digo

---

## CÃ³mo Ejecutar el Proyecto

### âœ…1. Clonar y configurar el entorno

git clone <tu-repositorio>
cd <carpeta-del-proyecto>
conda env create -f conda.yaml
conda activate wine-mlflow-genai
AsegÃºrate de tener Ollama instalado y el modelo llama3 descargado:


Copiar cÃ³digo
ollama pull llama3
2. Entrenar modelos (3 experimentos con hiperparÃ¡metros distintos)
bash
Copiar cÃ³digo
mlflow run . -P n_estimators=50  -P max_depth=5
mlflow run . -P n_estimators=100 -P max_depth=10
mlflow run . -P n_estimators=200 -P max_depth=None
3. Visualizar experimentos y promover a producciÃ³n
bash
Copiar cÃ³digo
mlflow ui
Luego accede a:

http://localhost:5000

Compara los runs

Registra el mejor modelo como WineQualityModel

Promueve una versiÃ³n a Staging, luego a Production

4. Ejecutar la interfaz de usuario
bash
Copiar cÃ³digo
cd gradio_app
python app.py
Tu navegador abrirÃ¡:

ðŸ“Ž http://localhost:7860

Ingresa valores o usa ejemplos predefinidos

Â¡ObtÃ©n predicciones + explicaciones generadas por IA!

Dataset
Fuente: UCI Machine Learning Repository â€“ Wine Quality

CaracterÃ­sticas: 11 atributos quÃ­micos (acidez, alcohol, azÃºcar residual, etc.)

Objetivo: Calidad del vino (escala entera 0â€“10)

Tipo de problema: RegresiÃ³n

Generative AI (Explicaciones)
Cuando se realiza una predicciÃ³n, el sistema llama a Ollama + Llama3 para generar una explicaciÃ³n como:

"Este vino tiene alta calidad porque presenta un contenido de alcohol elevado (10.5%) y baja acidez volÃ¡til (0.27 g/dmÂ³), lo que indica equilibrio y estabilidad."

AdemÃ¡s, la explicaciÃ³n se registra automÃ¡ticamente como artefacto en MLflow.

Entrega Final
Este repositorio incluye:

âœ… CÃ³digo fuente modular y reproducible
âœ… Notebook de exploraciÃ³n de datos
âœ… Interfaz Gradio funcional
âœ… Capturas de MLflow UI (incluidas en el informe)

Autores
Nombres: Juan Mosquera, Anderson Bornachera
Curso: MLOps â€“ Universidad del Magdalena
Fecha: Noviembre 2025
